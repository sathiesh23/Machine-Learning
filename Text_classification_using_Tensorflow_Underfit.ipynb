{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"19F9WjZ0Zh54xh_1svcLvMTjflGJeEPrW","timestamp":1670968081671}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"AWNaJJxXs2xT"},"source":["**Under fitting Model**: Model doesnot have enough parameters to learn the pattern in the training data.\n","\n","**Training Error -> Increases, Validation Error -> Increases**"]},{"cell_type":"markdown","metadata":{"id":"FmXBBt0btXOr"},"source":["Dataset: IMDB Movie Review Dataset"]},{"cell_type":"code","metadata":{"id":"-GNRKX_nsuTb","executionInfo":{"status":"ok","timestamp":1670968553517,"user_tz":-330,"elapsed":3304,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"}}},"source":["# import the necessary packages\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","from matplotlib import pyplot as plt\n","import numpy as np\n","#!pip install tensorflow==2.1.0\n","import tensorflow as tf\n","from tensorflow import keras"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TeQbtxLuemW"},"source":["# Load the dataset from keras package\n","NUM_WORDS=10000\n","(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)\n","print(\"Training entries: {}, Test entries: {}\".format(len(train_data), len(test_data)))\n","print(train_data[:10])\n","print(train_labels[:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FaZUn6Z-vL8E","executionInfo":{"status":"ok","timestamp":1670968571259,"user_tz":-330,"elapsed":510,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"}}},"source":["# Create a function for Multi-hot Sequences\n","# Multihot encoding turns our list of words into a vector of 0's and 1's\n","# Set specific indices of results[i] is set to 1\n","def multi_hot_sequences(sequences, dimension):\n","  results = np.zeros((len(sequences), dimension))\n","  for i, word_indices in enumerate(sequences):\n","    results[i, word_indices]=1.0\n","  return results"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"fri7qw0SwFlM"},"source":["# 10000 dimension vector is created\n","# it is done to ensure that all the messages are of equal length\n","train_data = multi_hot_sequences(train_data, dimension = NUM_WORDS)\n","test_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)\n","print(train_data[0])\n","plt.plot(train_data[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dhY6YTcf00OD"},"source":["## Demonstrate Underfitting:"]},{"cell_type":"code","metadata":{"id":"y2Yme0mv0v9G"},"source":["# Create a Standard baseline model\n","std_model = tf.keras.Sequential()\n","std_model.add(tf.keras.layers.Dense(16, activation='relu', input_shape = (NUM_WORDS,)))\n","#std_model.add(tf.keras.layers.Dense(16, activation='relu'))\n","std_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","\n","std_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UfFopsNt14wG","executionInfo":{"status":"ok","timestamp":1670968591382,"user_tz":-330,"elapsed":514,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"}}},"source":["# Set the optimizer and loss function to the model\n","std_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"omk8xyeU2bCd"},"source":["# Train the model for 10 epochs\n","std_history = std_model.fit(train_data, train_labels, epochs = 10, batch_size=512, validation_data=(test_data,test_labels), verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jffLKhk24u-1"},"source":["## Create a Small Network"]},{"cell_type":"code","metadata":{"id":"B3sef5PQ43aO"},"source":["# Create a Small model\n","small_model = tf.keras.Sequential()\n","small_model.add(tf.keras.layers.Dense(4, activation='relu', input_shape = (NUM_WORDS,)))\n","#small_model.add(tf.keras.layers.Dense(4, activation='relu'))\n","small_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","\n","small_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AEuzkFW25NRz","executionInfo":{"status":"ok","timestamp":1670968630146,"user_tz":-330,"elapsed":1070,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"}}},"source":["# Set the optimizer and loss function to the model\n","small_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoaY3I7F5Uer"},"source":["# Train the model for 10 epochs\n","small_history = small_model.fit(train_data, train_labels, epochs = 10, batch_size=512, validation_data=(test_data,test_labels), verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HmuIF22aCVY1"},"source":["# Plot the models\n","plt.plot(std_history.history['loss'], 'r', small_history.history['loss'], 'b')\n","plt.xlabel('Epochs')\n","plt.ylabel('Training Loss')\n","plt.legend(['std_model','small_model'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATKBgxs0FC_W"},"source":["# Plot the models\n","plt.plot(std_history.history['val_loss'], 'r--', small_history.history['val_loss'])\n","plt.xlabel('Epochs')\n","plt.ylabel('Validation loss')\n","plt.legend(['std_model','small_model'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pl4MNzU8RkNr"},"source":[],"execution_count":null,"outputs":[]}]}